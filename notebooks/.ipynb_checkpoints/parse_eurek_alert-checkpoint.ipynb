{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "def extract_related_journal_article_link(soup):\n",
    "    related_journal_article_link = None\n",
    "    related_journal_article_block = soup.find(class_='widget hidden-print')\n",
    "    print(related_journal_article_block)\n",
    "    if related_journal_article_block:\n",
    "        related_journal_article_link_tag = related_journal_article_block.find('a', rel='nofollow')\n",
    "        if related_journal_article_link_tag:\n",
    "            related_journal_article_link = related_journal_article_link_tag['href']\n",
    "    return related_journal_article_link\n",
    "'''\n",
    "\n",
    "def extract_links(soup):\n",
    "    \n",
    "    original_source_link = None\n",
    "    related_journal_article = None\n",
    "    \n",
    "    original_source_tag = soup.find('h4', text='Original Source')\n",
    "    if original_source_tag:\n",
    "        original_source_link = original_source_tag.find_next('a')['href']\n",
    "    \n",
    "    related_journal_article_tag = soup.find('h4', text='Related Journal Article')\n",
    "    if related_journal_article_tag:\n",
    "        related_journal_article = related_journal_article_tag.find_next('a')['href']\n",
    "    \n",
    "    return original_source_link, related_journal_article\n",
    "\n",
    "def extract_php_file_data(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as php_file:\n",
    "            php_code = php_file.read()\n",
    "            soup = BeautifulSoup(php_code, 'html.parser')\n",
    "            \n",
    "            release_date = soup.find(class_='release_date').text.strip()\n",
    "            page_title = soup.find(class_='page_title').text.strip()\n",
    "            meta_institute = soup.find(class_='meta_institute').text.strip()\n",
    "            \n",
    "            media_contact_div = soup.find(class_='contact-info')\n",
    "            media_contact = extract_media_contact(media_contact_div)\n",
    "            \n",
    "            keywords_ul = soup.find(class_='tags')\n",
    "            keywords = extract_keywords(keywords_ul)\n",
    "            \n",
    "            source_link, doi_link = extract_links(soup)\n",
    "            \n",
    "            full_text = clean_text(soup.get_text())\n",
    "            \n",
    "            return {\n",
    "                'release_date': release_date,\n",
    "                'page_title': page_title,\n",
    "                'meta_institute': meta_institute,\n",
    "                'media_contact': media_contact,\n",
    "                'keywords': keywords,\n",
    "                'full_text': full_text,\n",
    "                'original_source': source_link,\n",
    "                'related_journal_article_link': doi_link\n",
    "            }\n",
    "    except Exception as e:\n",
    "        #print(f\"An error occurred while parsing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def extract_media_contact(media_contact_div):\n",
    "    contact_info = {}\n",
    "    if media_contact_div:\n",
    "        strong_tag = media_contact_div.find('strong', string='Media Contact')\n",
    "        \n",
    "        if strong_tag:\n",
    "            paragraphs = media_contact_div.find_all('p')\n",
    "            if paragraphs:\n",
    "                contact_info['name'] = paragraphs[1].get_text().strip().split('\\n')[0]\n",
    "                email_link = paragraphs[1].find('a', href=re.compile(r'mailto:'))\n",
    "                if email_link:\n",
    "                    contact_info['email'] = email_link['href'].replace('mailto:', '').strip()\n",
    "                phone_match = re.match(r'(\\d{2,}-\\d{2,})', paragraphs[1].get_text().strip())\n",
    "                if phone_match:\n",
    "                    contact_info['phone'] = phone_match.group(1)\n",
    "                twitter_link = paragraphs[1].find('a', href=re.compile(r'twitter\\.com'))\n",
    "                if twitter_link:\n",
    "                    contact_info['twitter'] = twitter_link.get_text().replace('@', '').strip()\n",
    "                website_link = paragraphs[-1].find('a', href=re.compile(r'http'))\n",
    "                if website_link:\n",
    "                    contact_info['website'] = website_link['href'].strip()\n",
    "    return contact_info\n",
    "    \n",
    "#def extract_media_contact(media_contact_div):\n",
    "#    if media_contact_div:\n",
    "#        media_contact_text = media_contact_div.get_text()\n",
    "#        return media_contact_text.strip()\n",
    "#    return None\n",
    "\n",
    "def extract_keywords(keywords_ul):\n",
    "    if keywords_ul:\n",
    "        keywords = [keyword.get_text() for keyword in keywords_ul.find_all('a')]\n",
    "        return keywords\n",
    "    return []\n",
    "\n",
    "def clean_text(text):\n",
    "    # Replace multiple consecutive newline characters with one newline character using regex\n",
    "    cleaned_text = re.sub(r'\\n+', '\\n', text)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def save_to_jsonl(parsed_data, output_file):\n",
    "    with open(output_file, 'w') as jsonl_file:\n",
    "        for data in parsed_data:\n",
    "            jsonl_file.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-124-9ffec3e89e8c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-124-9ffec3e89e8c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    https://archive.eurekalert.org/pub_releases/2018-09/hu-mts090418.php\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://archive.eurekalert.org/pub_releases/2018-09/hu-mts090418.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-132-f29fce32db4f>:19: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  original_source_tag = soup.find('h4', text='Original Source')\n",
      "<ipython-input-132-f29fce32db4f>:23: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  related_journal_article_tag = soup.find('h4', text='Related Journal Article')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'release_date': 'Public Release:\\xa04-Sep-2018',\n",
       " 'page_title': 'Methane to syngas catalyst: two for the price of one',\n",
       " 'meta_institute': 'Hokkaido University',\n",
       " 'media_contact': {'name': 'Naoki Namba',\n",
       "  'twitter': 'hokkaidouni',\n",
       "  'website': 'https://www.global.hokudai.ac.jp/'},\n",
       " 'keywords': ['ATOMIC/MOLECULAR/PARTICLE PHYSICS',\n",
       "  'CHEMISTRY/PHYSICS/MATERIALS SCIENCES',\n",
       "  'CLIMATE CHANGE',\n",
       "  'CLIMATE CHANGE',\n",
       "  'ENERGY SOURCES',\n",
       "  'ENERGY/FUEL (NON-PETROLEUM)',\n",
       "  'MOLECULAR PHYSICS'],\n",
       " 'full_text': 'Methane to syngas catalyst: two for the price of one | EurekAlert! Science News\\n Skip to main content\\nAdvanced Search\\nHome\\nCOVID-19\\nNews Releases\\nLatest News Releases\\nNews By Subject \\nAgriculture\\nArchaeology\\nAtmospheric Science\\nBiology\\nBusiness & Economics\\nChemistry & Physics\\nEarth Science\\nEducation\\nMathematics\\nMedicine & Health\\nPolicy & Ethics\\nSocial & Behavioral\\nSpace & Planetary\\nTech & Engineering\\nScience Business Announcements\\nGrants, Awards, Books\\nLanguages \\nAuf Deutsch\\nEn Español\\nEn Français\\nEm Português\\n日本語\\n中文\\nPortals \\nClimate Change\\nCancer Research\\nMarine Science\\n\\xa0 E-mail Newsletter\\nLatest News Releases\\nScience Business Announcements\\nGrants\\nAwards\\nBooks\\n E-mail Newsletter\\n RSS Feeds\\nAgriculture\\nArchaeology\\nAtmospheric Science\\nBiology\\nBusiness & Economics\\nChemistry & Physics\\nEarth Science\\nEducation\\nMathematics\\nMedicine & Health\\nPolicy & Ethics\\nSocial & Behavior\\nSpace & Planetary\\nTech & Engineering\\nAuf Deutsch\\nEn Español\\nEn Français\\nEm Português\\n日本語\\n中文\\nMultimedia\\nAll multimedia\\nImages\\nVideo\\nAudio\\nSearch multimedia\\nAll Multimedia \\nSearch Multimedia\\nImages \\nVideo \\nAudio \\nMeetings\\nMeeting Announcements\\nMeetings Calendar\\nFeatured Newsrooms:\\nAAAS Annual Meeting 2021\\n8 - 11 February 2021\\n                          Virtual\\n                          \\nACS Spring 2021\\n5 - 30 April 2021\\n                            Virtual\\n                          \\nMeeting Announcements\\nMeetings Calendar\\nFeatured Newsrooms\\n\\xa0\\nPortals\\nHello World\\nFoo Bar\\nDropdown Menu \\nHello World\\nFoo Bar\\nAnother Link\\nThe Last Item\\nClimate ChangeThe latest insights into the changing climate\\nMore \\nCancer ResearchNew findings in cancer treatment and prevention\\nMore \\nMarine ScienceIn-depth investigations on all things marine science\\nMore \\nScience Agencies\\nUS Department of Energy\\nUS National Institutes of Health\\nUS National Science Foundation\\nAbout\\nAbout EurekAlert!\\nFor Reporters\\nFor PIOs\\nFAQ\\nSubscribe / Sponsor\\nContact EurekAlert!\\nNews Release Eligibility Guidelines\\nAbout EurekAlert!\\nFAQ\\nSubscribe / Sponsor\\nContact EurekAlert!\\nNews Release Eligibility Guidelines\\nFor Reporters\\nEurekAlert! provides eligible reporters with free access to embargoed and breaking news releases.Eligibility Guidelines \\nFor PIOS\\nEurekAlert! offers eligible public information officers paid access to a reliable news release distribution service.Eligibility Guidelines  \\nEurekAlert! is a service of the American Association for the Advancement of Science.\\nLogin\\nRegister\\nPublic Release:\\xa04-Sep-2018\\n                    Methane to syngas catalyst: two for the price of one\\n                \\nHokkaido University\\nShare\\n\\xa0Print\\n\\xa0E-Mail\\nIMAGE:\\xa0The proposed mechanism in which the hydrogen atoms spill over onto zeolite support, which then turns the cobalt oxide back into cobalt, keeping the catalyst active.\\n     view more\\xa0\\nCredit: Yuhui Hou et al., Communications Chemistry, August 1, 2018\\nHokkaido University researchers have created an improved catalyst for the conversion of methane gas into syngas, a precursor for liquid fuels and fundamental chemicals. \\nSyngas, also known as synthesis gas, is a mixture made primarily of carbon monoxide and hydrogen and is used to manufacture polymers, pharmaceuticals, and synthetic petroleum. It is made by exposing methane to water vapor at 900 °C or higher, making the process costly. \\nThe partial oxidation of methane for syngas synthesis is more economical than using steam but there have been issues with the catalysts used for this process. Noble metal catalysts, such as rhodium and platinum, are better and work at lower temperatures than base metal catalysts, such as cobalt and nickel, but they are also more expensive. The cheaper base metal catalysts require temperatures above 800 °C, exceeding the temperature range for industrial stainless-steel reactors. They are also deactivated during the reaction by re-oxidation and the accumulation of coke, a by-product of the process, making them costly in the long-term.\\nAssistant Professor Hirokazu Kobayashi, Professor Atsushi Fukuoka, and postdoctoral fellow Yuhui Hou, working in Hokkaido University\\'s Institute for Catalysis, succeeded in preparing a catalyst that combines the properties of both noble and base metals. Their catalyst overcomes challenges faced by previous studies in adding a small enough amount of noble metal to the base metal catalyst that it can still work at lower temperatures.\\nIn the study published in Communications Chemistry, the team successfully generated tiny particles of the base metal cobalt by dispersing them onto a mineral deposit called zeolite. They then added a minute amount of noble metal rhodium atoms onto the cobalt particles. \\nThe new, combined catalyst successfully converted 86% of methane to syngas at 650 °C while maintaining its activity for at least 50 hours. The reaction oxidizes cobalt to cobalt oxide, which is nearly inactive. But because the rhodium is contained, the noble metal generates hydrogen atoms from methane or hydrogen molecules. The hydrogen atoms spill over onto the supporting material, and the spillover hydrogen turns the cobalt oxide back into cobalt. The cobalt can then continue to act as a catalyst. The high dispersion of cobalt on zeolite also prevented the formation of coke during the reaction.\\nMethane has drawn attention as a source of clean energy as it produces only a half amount of CO2 compared to petroleum when burned. Moreover, increased shale gas mining has made methane a more accessible resource. \"Our catalyst can efficiently convert methane to syngas at 650 °C, a much lower temperature than in conventional methods. This could lead to more efficient use of methane and contribute to the development of a low-carbon society,\" says Hirokazu Kobayashi.\\n###\\nDisclaimer: AAAS and EurekAlert! are not responsible for the accuracy of news releases posted to EurekAlert! by contributing institutions or for the use of any information through the EurekAlert system.\\nShare\\n\\xa0Print\\n\\xa0E-Mail\\nMedia Contact\\nNaoki Namba\\n011-706-2185\\n\\xa0@hokkaidouni\\nhttps://www.global.hokudai.ac.jp/\\xa0\\nMore on this News Release\\nMethane to syngas catalyst: two for the price of one\\nHokkaido University\\nJournal\\nCommunications Chemistry\\nFunder\\nJapan Science and Technology Agency,CREST Grant\\nKeywords\\nATOMIC/MOLECULAR/PARTICLE PHYSICS\\nCHEMISTRY/PHYSICS/MATERIALS SCIENCES\\nCLIMATE CHANGE\\nCLIMATE CHANGE\\nENERGY SOURCES\\nENERGY/FUEL (NON-PETROLEUM)\\nMOLECULAR PHYSICS\\nMultimedia\\nProposed Mechanism (IMAGE)\\nview more\\xa0\\nOriginal Source\\nhttps://www.global.hokudai.ac.jp/blog/methane-to-syngas-catalyst-two-for-the-price-of-one/ \\nRelated Journal Article\\nhttp://dx.doi.org/10.1038/s42004-018-0044-9 \\nMore in Chemistry & Physics\\nThrough the thin-film glass, researchers spot a new liquid phase\\nUniversity of Pennsylvania\\nDalian Coherent Light Source reveals strong isotope effects in photodissociation of water isotopolog\\nDalian Institute of Chemical Physics, Chinese Academy Sciences\\nCascaded metasurfaces for dynamic control of THz wavefronts\\nSPIE--International Society for Optics and Photonics\\nBio-based coating for wood outperforms traditional synthetic options\\nAalto University\\nView all in Chemistry & Physics\\xa0\\nTrending News Releases\\n\\'Golden nail\\': Quarry near Salzgitter becomes global geological reference point\\nGoethe University Frankfurt\\nInvestigational magnetic device shrinks glioblastoma in first-in-world human test\\nHouston Methodist\\n\\'Good cholesterol\\' may protect liver\\nWashington University School of Medicine\\n\\'Feel good\\' brain messenger can be willfully controlled, new study reveals\\nUniversity of California - San Diego\\nView all latest news releases\\xa0\\nCopyright © 2023 by the American Association for the Advancement of Science (AAAS)\\nLatest News Releases RSS Feed\\nAll EurekAlert! RSS Feeds\\n@EurekAlert\\nfacebook.com/EurekAlert\\nHelp / FAQ\\nDisclaimer\\nPrivacy Policy\\nTerms & Conditions\\nContact EurekAlert!\\nCopyright © 2023 by the American Association for the Advancement of Science (AAAS)',\n",
       " 'original_source': 'https://www.global.hokudai.ac.jp/blog/methane-to-syngas-catalyst-two-for-the-price-of-one/',\n",
       " 'related_journal_article_link': 'http://dx.doi.org/10.1038/s42004-018-0044-9'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2018-09/hu-mts090418.php\"\n",
    "extract_php_file_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(subdir_path):\n",
    "    parsed_data = []\n",
    "    for file in os.listdir(subdir_path):\n",
    "        if file.endswith('.php'):\n",
    "            file_path = os.path.join(subdir_path, file)\n",
    "            data = extract_php_file_data(file_path)\n",
    "            if data:\n",
    "                parsed_data.append(data)\n",
    "    \n",
    "    output_file = output_file = subdir_path.replace('pub_releases', 'extracted') + '.jsonl'\n",
    "    save_to_jsonl(parsed_data, output_file)\n",
    "    print(len(parsed_data), 'lines saved to', output_file)\n",
    "\n",
    "def process(base_directory):\n",
    "    with Pool(processes=12) as pool:\n",
    "        pool.map(process_directory, [os.path.join(base_directory, subdir) for subdir in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, subdir))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2000-09/AAft-Cmit-1109100.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2000-09/AAft-Gmff-1109100.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2000-09/AAft-Pcfo-2809100.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1999-07/AFMP-BbAm-170799.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2000-09/AAft-TeiU-1909100.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2002-06/aaft-wlo062402.php: 'NoneType' object has no attribute 'text'\n",
      "10 lines saved to /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/extracted/1969-12.jsonl\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2001-11/aaon-ebs111901.php: 'utf-8' codec can't decode byte 0x92 in position 1602: invalid start byte\n",
      "4 lines saved to /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/extracted/1996-01.jsonl\n",
      "1 lines saved to /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/extracted/1996-03.jsonl\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1998-05/AGU-PCSF-270598.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2002-06/aaop-tyh062002.php: 'utf-8' codec can't decode byte 0x92 in position 1523: invalid start byte\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2000-09/ACS-Nbsf-1709100.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2000-02/AHA-Inpr-1002100.php: 'utf-8' codec can't decode byte 0x92 in position 1493: invalid start byte\n",
      "27 lines saved to /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/extracted/1996-04.jsonl\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2001-11/acs-wls113001.php: 'utf-8' codec can't decode byte 0x92 in position 1739: invalid start byte\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2001-11/acs-wls_1113001.php: 'utf-8' codec can't decode byte 0x92 in position 1748: invalid start byte\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1998-12/AUA-AUAM-081298.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1998-05/AUA-AAOV-310598.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1998-05/AUA-APAT-310598.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1998-05/AUA-ENFB-310598.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/2001-04/ACS-Rfac-0804101.php: 'utf-8' codec can't decode byte 0xae in position 1796: invalid start byte\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1998-05/AUA-EoSS-310598.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1998-05/AUA-FUON-310598.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1998-05/AUA-IRAO-310598.php: 'NoneType' object has no attribute 'text'\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1998-05/AUA-IVFP-310598.php: 'NoneType' object has no attribute 'text'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-16:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-2fa7572c6cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-114-d9fba3b1bc5a>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(base_directory)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_directory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "directory_path = '/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/'\n",
    "process(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [00:01<00:00, 248.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 472821 valid files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 92/1000 [00:04<00:38, 23.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-06/CUNS-TDOC-240696.php: 'utf-8' codec can't decode byte 0xad in position 1512: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 632/1000 [00:28<00:14, 25.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-11/UoG-UOGS-081196.php: 'utf-8' codec can't decode byte 0x9e in position 41626: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:50<00:00, 19.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998 lines saved\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "directory_path = '/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/'\n",
    "save_dir = '/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/extracted/'\n",
    "\n",
    "\n",
    "filepaths = []\n",
    "for subdir in tqdm(os.listdir(directory_path)):\n",
    "    subdir_path = os.path.join(directory_path, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        for file in os.listdir(subdir_path):\n",
    "            if file.endswith('.php'):\n",
    "                file_path = os.path.join(subdir_path, file)\n",
    "                filepaths.append(file_path)\n",
    "            \n",
    "print('find %s valid files'%len(filepaths))\n",
    "\n",
    "parsed_data = []\n",
    "for file_path in tqdm(filepaths[:1000]):\n",
    "    data = extract_php_file_data(file_path)\n",
    "    if data:\n",
    "        parsed_data.append(data)\n",
    "\n",
    "save_to_jsonl(parsed_data, '/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/all_extracted.jsonl')\n",
    "print(len(parsed_data), 'lines saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1969-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 lines saved\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 lines saved\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-03\n",
      "1 lines saved\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:01,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 lines saved\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 lines saved\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-06\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-06/CUNS-TDOC-240696.php: 'utf-8' codec can't decode byte 0xad in position 1512: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:05,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 lines saved\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:09,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 lines saved\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:12,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 lines saved\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:15,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 lines saved\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:20,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 lines saved\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-11\n",
      "An error occurred while parsing /shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-11/UoG-UOGS-081196.php: 'utf-8' codec can't decode byte 0x9e in position 41626: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:26,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 lines saved\n",
      "/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/1996-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:27,  2.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-e2b61d032823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.php'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_php_file_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mparsed_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-49b0c9c1e81a>\u001b[0m in \u001b[0;36mextract_php_file_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mkeywords_ul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords_ul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mfull_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-49b0c9c1e81a>\u001b[0m in \u001b[0;36mextract_keywords\u001b[0;34m(keywords_ul)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords_ul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeywords_ul\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords_ul\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36mfind_all\u001b[0;34m(self, name, attrs, recursive, string, limit, **kwargs)\u001b[0m\n\u001b[1;32m   2028\u001b[0m             \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \u001b[0m_stacklevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_stacklevel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2030\u001b[0;31m         return self._find_all(name, attrs, string, limit, generator,\n\u001b[0m\u001b[1;32m   2031\u001b[0m                               _stacklevel=_stacklevel+1, **kwargs)\n\u001b[1;32m   2032\u001b[0m     \u001b[0mfindAll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_all\u001b[0m       \u001b[0;31m# BS3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m_find_all\u001b[0;34m(self, name, attrs, string, limit, generator, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m                           )\n\u001b[1;32m    832\u001b[0m                 )\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mResultSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResultSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, result)\u001b[0m\n\u001b[1;32m   2421\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mPageElements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \"\"\"\n\u001b[0;32m-> 2423\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResultSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2424\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    823\u001b[0m                     \u001b[0mlocal_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                 result = (element for element in generator\n\u001b[0;32m--> 825\u001b[0;31m                           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                           and (\n\u001b[1;32m    827\u001b[0m                               \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "directory_path = '/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/pub_releases/'\n",
    "save_dir = '/shared/3/projects/jiaxin/datasets/eurekalert/wget/archive.eurekalert.org/extracted/'\n",
    "\n",
    "\n",
    "for root, _, files in tqdm(os.walk(directory_path)):\n",
    "    print(root)\n",
    "    parsed_data = []\n",
    "    for file in files:\n",
    "        if file.endswith('.php'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            data = extract_php_file_data(file_path)\n",
    "            if data:\n",
    "                parsed_data.append(data)\n",
    "    if len(parsed_data) > 0:\n",
    "        save_to_jsonl(parsed_data, root.replace('pub_releases', 'extracted') + '.jsonl')\n",
    "        print(len(parsed_data), 'lines saved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
